{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ravikumar/Developer/upwork/RAG-Video-Transcription\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "os.chdir(\"../\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-29 20:52:06--  https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2404:6800:4007:822::201b, 2404:6800:4007:80a::201b, 2404:6800:4007:814::201b, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2404:6800:4007:822::201b|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 238090979 (227M) [video/mp4]\n",
      "Saving to: ‘data/videos/GreatRedSpot.mp4’\n",
      "\n",
      "GreatRedSpot.mp4    100%[===================>] 227.06M  12.0MB/s    in 20s     \n",
      "\n",
      "2024-11-29 20:52:27 (11.2 MB/s) - ‘data/videos/GreatRedSpot.mp4’ saved [238090979/238090979]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data\n",
    "!wget -P data/videos https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file_name = \"data/videos/GreatRedSpot.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file...\n",
      "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/lzdkbl12fbm5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Uploading file...\")\n",
    "video_file = genai.upload_file(path=video_file_name)\n",
    "print(f\"Completed upload: {video_file.uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT_TRANSCRIPT_TEMPLATE = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt.\n",
    "prompt = \"Transcribe the audio from this video, giving timestamps for salient events in the video. \"\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if video_file.state.name == \"PROCESSING\":\n",
    "    time.sleep(10)\n",
    "    video_file = genai.get_file(video_file.name)\n",
    "if video_file.state.name == \"FAILED\":\n",
    "    raise ValueError(video_file.state.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIBE_VIDEO_PROMPT = \"\"\"\n",
    "Transcribe the video audio into the WEBVTT format as shown below:\n",
    "\n",
    "WEBVTT\n",
    "\n",
    "00:00:46.000 --> 00:00:50.020\n",
    "<v SpeakerName>OK, So this is our agenda for today.</v>\n",
    "\n",
    "00:00:50.440 --> 00:00:51.050\n",
    "<v SpeakerName>OK.</v>\n",
    "\n",
    "00:00:51.710 --> 00:00:53.640\n",
    "<v SpeakerName>Timewise, we're probably talking about a couple of hours.</v>\n",
    "\n",
    "- Use exact timestamps.\n",
    "- Replace \"SpeakerName\" with the actual speaker's name if provided.\n",
    "- Maintain accuracy in both the transcription and formatting.\n",
    "- Use the speaker tag format <v SpeakerName> and </v> consistently.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\n",
    "    [video_file, TRANSCRIBE_VIDEO_PROMPT], request_options={\"timeout\": 1200}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Absolutely! Here's the transcript in WEBVTT format:\\n\\n```webvtt\\nWEBVTT\\n\\n00:00.000 --> 00:08.000\\n<v Narrator>Jupiter is the largest and oldest planet in our solar system. Its history spans 4.5 billion years.\\n\\n00:10.000 --> 00:15.000\\n<v Narrator>This gas giant is made of the same elements as a star, but it did not grow massive enough to ignite.\\n\\n00:18.000 --> 00:28.000\\n<v Narrator>Jupiter's appearance is the result of its swirling interior of gases and liquids, producing a tapestry of colorful cloud bands, as well as the iconic Great Red Spot.\\n\\n00:33.000 --> 00:45.000\\n<v Narrator>The Great Red Spot is a gigantic storm. It's an anticyclone, and with no land mass on the planet to slow it down, the Great Red Spot has raged for over a century.\\n\\n00:48.000 --> 00:56.000\\n<v Narrator>But, scientists studying the spot have noticed that it has been changing over time. The color is deepening, and it's actually shrinking and getting rounder.\\n\\n00:58.000 --> 01:04.000\\n<v Narrator>Those studying it expected to therefore see the wind speeds inside the Great Red Spot increasing as the storm shrinks, like an ice skater who spins faster as she pulls in her arms.\\n\\n01:09.000 --> 01:17.000\\n<v Narrator>But, this isn't the case. Data reveals the storm isn't spinning faster. It's actually getting taller. You can think of it like working with pottery.\\n\\n01:19.000 --> 01:30.000\\n<v Narrator>As the wide lump of clay spins, forces within are driving it taller. So from our perspective looking down on the clouds, we see the spot getting smaller and rounder.\\n\\n01:30.000 --> 01:35.000\\n<v Narrator>The Great Red Spot used to be big enough to fit three Earths. Now, it's just a little over one.\\n\\n01:37.000 --> 01:45.000\\n<v Narrator>These discoveries were made by analyzing data from numerous NASA missions, including Voyager, Hubble, and most recently, Juno.\\n\\n01:48.000 --> 01:54.000\\n<v Narrator>And through more investigations, scientists hope to unlock more secrets of the mysterious Great Red Spot.\\n\\n```\\n\\nLet me know if there are any other adjustments you need!\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Absolutely! Here's the transcript in WEBVTT format:\",\n",
       " '```webvtt\\nWEBVTT',\n",
       " '00:00.000 --> 00:08.000\\n<v Narrator>Jupiter is the largest and oldest planet in our solar system. Its history spans 4.5 billion years.',\n",
       " '00:10.000 --> 00:15.000\\n<v Narrator>This gas giant is made of the same elements as a star, but it did not grow massive enough to ignite.',\n",
       " \"00:18.000 --> 00:28.000\\n<v Narrator>Jupiter's appearance is the result of its swirling interior of gases and liquids, producing a tapestry of colorful cloud bands, as well as the iconic Great Red Spot.\",\n",
       " \"00:33.000 --> 00:45.000\\n<v Narrator>The Great Red Spot is a gigantic storm. It's an anticyclone, and with no land mass on the planet to slow it down, the Great Red Spot has raged for over a century.\",\n",
       " \"00:48.000 --> 00:56.000\\n<v Narrator>But, scientists studying the spot have noticed that it has been changing over time. The color is deepening, and it's actually shrinking and getting rounder.\",\n",
       " '00:58.000 --> 01:04.000\\n<v Narrator>Those studying it expected to therefore see the wind speeds inside the Great Red Spot increasing as the storm shrinks, like an ice skater who spins faster as she pulls in her arms.',\n",
       " \"01:09.000 --> 01:17.000\\n<v Narrator>But, this isn't the case. Data reveals the storm isn't spinning faster. It's actually getting taller. You can think of it like working with pottery.\",\n",
       " '01:19.000 --> 01:30.000\\n<v Narrator>As the wide lump of clay spins, forces within are driving it taller. So from our perspective looking down on the clouds, we see the spot getting smaller and rounder.',\n",
       " \"01:30.000 --> 01:35.000\\n<v Narrator>The Great Red Spot used to be big enough to fit three Earths. Now, it's just a little over one.\",\n",
       " '01:37.000 --> 01:45.000\\n<v Narrator>These discoveries were made by analyzing data from numerous NASA missions, including Voyager, Hubble, and most recently, Juno.',\n",
       " '01:48.000 --> 01:54.000\\n<v Narrator>And through more investigations, scientists hope to unlock more secrets of the mysterious Great Red Spot.',\n",
       " '```',\n",
       " 'Let me know if there are any other adjustments you need!']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text.split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import time\n",
    "# import google.generativeai as genai\n",
    "# from datetime import datetime\n",
    "# import re\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# # Load environment variables from .env file\n",
    "# load_dotenv()\n",
    "\n",
    "\n",
    "# def generate_vtt_filename(video_filename):\n",
    "#     \"\"\"Generate a VTT filename based on the video filename and current timestamp.\"\"\"\n",
    "#     base_name = os.path.splitext(os.path.basename(video_filename))[0]\n",
    "#     timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#     return f\"{base_name}_{timestamp}.vtt\"\n",
    "\n",
    "\n",
    "# def format_timestamp(timestamp):\n",
    "#     \"\"\"Format timestamp to ensure exactly 3 decimal places.\"\"\"\n",
    "#     # Split into seconds and milliseconds\n",
    "#     parts = timestamp.split('.')\n",
    "#     seconds = parts[0]\n",
    "#     # Ensure exactly 3 decimal places\n",
    "#     msec = parts[1][:3] if len(parts) > 1 else \"000\"\n",
    "#     msec = msec.ljust(3, '0')\n",
    "#     return f\"{seconds}.{msec}\"\n",
    "\n",
    "\n",
    "# def clean_vtt_content(content):\n",
    "#     \"\"\"Clean and format the VTT content.\"\"\"\n",
    "#     # Remove any markdown code block markers and extra text\n",
    "#     content = re.sub(r'```.*?\\n', '', content)\n",
    "#     content = re.sub(r'```', '', content)\n",
    "#     content = re.sub(r'WEBVTT file:', 'WEBVTT', content)\n",
    "    \n",
    "#     # Start with WEBVTT header\n",
    "#     formatted_lines = ['WEBVTT', '']\n",
    "    \n",
    "#     # Split content into lines and process\n",
    "#     lines = content.strip().split('\\n')\n",
    "    \n",
    "#     # Skip any existing WEBVTT header\n",
    "#     i = 0\n",
    "#     while i < len(lines) and (not lines[i].strip() or lines[i].strip().startswith('WEBVTT')):\n",
    "#         i += 1\n",
    "    \n",
    "#     # Process remaining lines\n",
    "#     while i < len(lines):\n",
    "#         line = lines[i].strip()\n",
    "        \n",
    "#         # Skip empty lines\n",
    "#         if not line:\n",
    "#             i += 1\n",
    "#             continue\n",
    "            \n",
    "#         # Process timestamp lines\n",
    "#         if '-->' in line:\n",
    "#             # Format timestamps\n",
    "#             times = line.split(' --> ')\n",
    "#             if len(times) == 2:\n",
    "#                 # Ensure HH:MM:SS format for timestamps\n",
    "#                 start_time = format_timestamp(times[0].strip())\n",
    "#                 end_time = format_timestamp(times[1].strip())\n",
    "#                 if ':' not in start_time:\n",
    "#                     start_time = f\"00:{start_time}\"\n",
    "#                 if ':' not in end_time:\n",
    "#                     end_time = f\"00:{end_time}\"\n",
    "#                 formatted_lines.append(f\"{start_time} --> {end_time}\")\n",
    "                \n",
    "#                 # Process speaker line\n",
    "#                 if i + 1 < len(lines):\n",
    "#                     speaker_line = lines[i + 1].strip()\n",
    "#                     if speaker_line:\n",
    "#                         formatted_lines.append(speaker_line)\n",
    "#                         formatted_lines.append('')  # Single blank line between entries\n",
    "#                     i += 2\n",
    "#                     continue\n",
    "#         i += 1\n",
    "    \n",
    "#     # Remove trailing empty lines and ensure single newline at end\n",
    "#     while formatted_lines and not formatted_lines[-1]:\n",
    "#         formatted_lines.pop()\n",
    "    \n",
    "#     return '\\n'.join(formatted_lines) + '\\n'\n",
    "\n",
    "\n",
    "# def save_vtt_content(content, output_path):\n",
    "#     \"\"\"Save the VTT content to a file.\"\"\"\n",
    "#     with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(content)\n",
    "#     print(f\"Saved transcript to: {output_path}\")\n",
    "\n",
    "\n",
    "# def transcribe_video(video_file_path, output_dir=\"data/transcripts\"):\n",
    "#     \"\"\"Transcribe video using Gemini and save as VTT file.\"\"\"\n",
    "#     # Configure Gemini\n",
    "#     genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "#     # Upload video file\n",
    "#     print(f\"Uploading file: {video_file_path}\")\n",
    "#     video_file = genai.upload_file(path=video_file_path)\n",
    "#     print(f\"Completed upload: {video_file.uri}\")\n",
    "\n",
    "#     # Check whether the file is ready to be used.\n",
    "#     while video_file.state.name == \"PROCESSING\":\n",
    "#         print(\".\", end=\"\")\n",
    "#         time.sleep(10)\n",
    "#         video_file = genai.get_file(video_file.name)\n",
    "\n",
    "#     if video_file.state.name == \"FAILED\":\n",
    "#         raise ValueError(video_file.state.name)\n",
    "\n",
    "#     # Initialize model\n",
    "#     model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
    "\n",
    "#     # Define transcription prompt\n",
    "#     TRANSCRIBE_VIDEO_PROMPT = \"\"\"\n",
    "#     Transcribe the video audio into WebVTT format following these exact rules:\n",
    "#     1. Start with only \"WEBVTT\" on the first line (no extra text)\n",
    "#     2. Add exactly one blank line after WEBVTT\n",
    "#     3. For each segment:\n",
    "#        - Use timestamps in format HH:MM:SS.mmm (exactly 3 decimal places)\n",
    "#        - Format: XX:XX:XX.XXX --> XX:XX:XX.XXX\n",
    "#        - Use speaker tags: <v Speaker>text</v>\n",
    "#        - Add exactly one blank line between segments\n",
    "#     4. Keep segments short (around 5-10 seconds each)\n",
    "#     5. Do not add any extra text or formatting\n",
    "\n",
    "#     Example format:\n",
    "#     WEBVTT\n",
    "\n",
    "#     00:00:46.000 --> 00:00:50.020\n",
    "#     <v Speaker>Text content goes here.</v>\n",
    "\n",
    "#     00:00:50.440 --> 00:00:51.050\n",
    "#     <v Speaker>Next segment text.</v>\n",
    "#     \"\"\"\n",
    "\n",
    "#     try:\n",
    "#         # Generate transcription\n",
    "#         print(\"Generating transcription...\")\n",
    "#         response = model.generate_content(\n",
    "#             [video_file, TRANSCRIBE_VIDEO_PROMPT], request_options={\"timeout\": 1200}\n",
    "#         )\n",
    "\n",
    "#         # Clean and format the response\n",
    "#         formatted_content = clean_vtt_content(response.text)\n",
    "\n",
    "#         # Create output directory if it doesn't exist\n",
    "#         os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#         # Generate output filename and save\n",
    "#         output_file = os.path.join(output_dir, generate_vtt_filename(video_file_path))\n",
    "#         save_vtt_content(formatted_content, output_file)\n",
    "\n",
    "#         return output_file\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error during transcription: {str(e)}\")\n",
    "#         raise\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Example usage\n",
    "#     video_file_path = \"data/videos/GreatRedSpot.mp4\"\n",
    "#     transcribe_video(video_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "# import time\n",
    "# from elasticsearch import Elasticsearch\n",
    "# from typing import List, Dict, Optional\n",
    "# import json\n",
    "# from datetime import datetime\n",
    "# from transcript_processor import TranscriptProcessor\n",
    "# from pathlib import Path\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# from langchain_elasticsearch import ElasticsearchStore\n",
    "# from langchain.schema import Document\n",
    "\n",
    "# class VideoTranscriptionStore:\n",
    "#     def __init__(self, videos_dir: str, transcripts_dir: str):\n",
    "#         self.vector_store = self.init_vector_store()\n",
    "#         self.processor = TranscriptProcessor(videos_dir, transcripts_dir)\n",
    "    \n",
    "#     def init_vector_store(self) -> ElasticsearchStore:\n",
    "#         # Initialize OpenAI embeddings\n",
    "#         embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "        \n",
    "#         # Wait for Elasticsearch to be ready\n",
    "#         es_client = Elasticsearch(\n",
    "#             \"http://localhost:9200\",\n",
    "#             basic_auth=(\"elastic\", \"changeme\")\n",
    "#         )\n",
    "        \n",
    "#         # Wait for up to 30 seconds for Elasticsearch to be ready\n",
    "#         start_time = time.time()\n",
    "#         while time.time() - start_time < 30:\n",
    "#             try:\n",
    "#                 if es_client.ping():\n",
    "#                     print(\"Successfully connected to Elasticsearch\")\n",
    "#                     break\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Waiting for Elasticsearch to be ready... {str(e)}\")\n",
    "#                 time.sleep(2)\n",
    "#         else:\n",
    "#             raise Exception(\"Could not connect to Elasticsearch after 30 seconds\")\n",
    "\n",
    "#         # Initialize vector store\n",
    "#         return ElasticsearchStore(\n",
    "#             es_url=\"http://localhost:9200\",\n",
    "#             index_name=\"video_transcriptions\",\n",
    "#             embedding=embeddings,\n",
    "#             es_user=\"elastic\",\n",
    "#             es_password=\"changeme\",\n",
    "#         )\n",
    "\n",
    "#     def upsert_video(self, video_filename: str) -> None:\n",
    "#         \"\"\"\n",
    "#         Process and upsert a single video's transcription.\n",
    "        \n",
    "#         Args:\n",
    "#             video_filename: Name of the video file\n",
    "#         \"\"\"\n",
    "#         try:\n",
    "#             # Process the video and its transcript\n",
    "#             result = self.processor.process_video(video_filename)\n",
    "            \n",
    "#             documents = []\n",
    "#             for segment in result[\"segments\"]:\n",
    "#                 # Create a Document object with the segment text and all metadata\n",
    "#                 doc = Document(\n",
    "#                     page_content=segment[\"text\"],\n",
    "#                     metadata={\n",
    "#                         **result[\"metadata\"],  # Include all video/transcript metadata\n",
    "#                         \"start_time\": segment[\"start_time\"],\n",
    "#                         \"end_time\": segment[\"end_time\"],\n",
    "#                     }\n",
    "#                 )\n",
    "#                 documents.append(doc)\n",
    "            \n",
    "#             # Add documents to the vector store\n",
    "#             self.vector_store.add_documents(documents)\n",
    "#             print(f\"Added {len(documents)} segments from video: {video_filename}\")\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing video {video_filename}: {str(e)}\")\n",
    "\n",
    "#     def upsert_all_videos(self) -> None:\n",
    "#         \"\"\"Process and upsert all videos in the videos directory.\"\"\"\n",
    "#         videos_dir = Path(self.processor.videos_dir)\n",
    "#         for video_file in videos_dir.glob(\"*.mp4\"):\n",
    "#             self.upsert_video(video_file.name)\n",
    "\n",
    "#     def search_transcriptions(\n",
    "#         self,\n",
    "#         query: str,\n",
    "#         filter_metadata: Optional[Dict] = None,\n",
    "#         k: int = 5\n",
    "#     ) -> List[Dict]:\n",
    "#         \"\"\"\n",
    "#         Search transcriptions using a natural language query.\n",
    "        \n",
    "#         Args:\n",
    "#             query: Search query\n",
    "#             filter_metadata: Optional metadata filters (e.g., {\"video_filename\": \"example.mp4\"})\n",
    "#             k: Number of results to return\n",
    "            \n",
    "#         Returns:\n",
    "#             List of relevant transcription segments with metadata\n",
    "#         \"\"\"\n",
    "#         # Perform the search\n",
    "#         results = self.vector_store.similarity_search_with_score(\n",
    "#             query,\n",
    "#             k=k,\n",
    "#             filter=filter_metadata\n",
    "#         )\n",
    "        \n",
    "#         # Format the results\n",
    "#         formatted_results = []\n",
    "#         for doc, score in results:\n",
    "#             result = {\n",
    "#                 \"text\": doc.page_content,\n",
    "#                 \"start_time\": doc.metadata[\"start_time\"],\n",
    "#                 \"end_time\": doc.metadata[\"end_time\"],\n",
    "#                 \"video_filename\": doc.metadata[\"video_filename\"],\n",
    "#                 \"relevance_score\": score,\n",
    "#             }\n",
    "            \n",
    "#             # Add all other metadata\n",
    "#             result[\"metadata\"] = {k: v for k, v in doc.metadata.items() \n",
    "#                                 if k not in [\"start_time\", \"end_time\", \"video_filename\"]}\n",
    "            \n",
    "#             formatted_results.append(result)\n",
    "        \n",
    "#         return formatted_results\n",
    "\n",
    "# def main():\n",
    "#     # Initialize the store with your video and transcript directories\n",
    "#     store = VideoTranscriptionStore(\n",
    "#         videos_dir=\"/Users/ravikumar/Developer/upwork/RAG-Video-Transcription/data/videos\",\n",
    "#         transcripts_dir=\"/Users/ravikumar/Developer/upwork/RAG-Video-Transcription/data/transcripts\"\n",
    "#     )\n",
    "    \n",
    "#     # Upsert all videos\n",
    "#     store.upsert_all_videos()\n",
    "    \n",
    "#     # Example search\n",
    "#     results = store.search_transcriptions(\n",
    "#         query=\"What is discussed about python tutorial?\",\n",
    "#         k=3\n",
    "#     )\n",
    "    \n",
    "#     # Print results\n",
    "#     print(\"\\nSearch Results:\")\n",
    "#     for result in results:\n",
    "#         print(f\"\\nSegment: {result['text']}\")\n",
    "#         print(f\"Video: {result['video_filename']}\")\n",
    "#         print(f\"Timestamp: {result['start_time']} - {result['end_time']}\")\n",
    "#         print(f\"Relevance Score: {result['relevance_score']}\")\n",
    "#         print(\"Additional Metadata:\", json.dumps(result[\"metadata\"], indent=2))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:00.000\n",
      "00:00:04.980\n",
      "Jupiter is the largest and oldest planet in our solar system.\n",
      "#########################\n",
      "00:00:04.980\n",
      "00:00:08.940\n",
      "Its history spans 4.5 billion years.\n",
      "#########################\n",
      "00:00:08.940\n",
      "00:00:15.900\n",
      "This gas giant is made of the same elements as a star, but it did not grow massive enough to ignite.\n",
      "#########################\n",
      "00:00:15.900\n",
      "00:00:21.840\n",
      "Jupiter's appearance is the result of its swirling interior of gases and liquids,\n",
      "#########################\n",
      "00:00:21.840\n",
      "00:00:28.740\n",
      "producing a tapestry of colorful cloud bands, as well as the iconic Great Red Spot.\n",
      "#########################\n",
      "00:00:28.740\n",
      "00:00:31.770\n",
      "\n",
      "#########################\n",
      "00:00:31.770\n",
      "00:00:41.730\n",
      "The Great Red Spot is a gigantic storm. It's an anticyclone, and with no land mass on the planet to slow it down, the Great Red Spot has raged for over a century.\n",
      "#########################\n",
      "00:00:41.730\n",
      "00:00:45.720\n",
      "\n",
      "#########################\n",
      "00:00:45.720\n",
      "00:00:47.700\n",
      "\n",
      "#########################\n",
      "00:00:47.700\n",
      "00:00:51.660\n",
      "But scientists studying the spot have noticed that it has been changing over time.\n",
      "#########################\n",
      "00:00:51.660\n",
      "00:00:56.610\n",
      "The color is deepening, and it's actually shrinking and getting rounder.\n",
      "#########################\n",
      "00:00:56.610\n",
      "00:01:04.560\n",
      "Those studying it expected to therefore see the wind speeds inside the Great Red Spot increasing as the storm shrinks, like an ice skater who spins faster as she pulls in her arms.\n",
      "#########################\n",
      "00:01:04.560\n",
      "00:01:08.460\n",
      "\n",
      "#########################\n",
      "00:01:08.460\n",
      "00:01:12.420\n",
      "\n",
      "#########################\n",
      "00:01:12.420\n",
      "00:01:17.370\n",
      "But this isn't the case. Data reveals the storm isn't spinning faster. It's actually getting taller.\n",
      "#########################\n",
      "00:01:17.370\n",
      "00:01:24.330\n",
      "You could think of it like working with pottery. As the wide lump of clay spins, forces within are driving it taller.\n",
      "#########################\n",
      "00:01:24.330\n",
      "00:01:30.270\n",
      "So from our perspective, looking down on the clouds, we see the spot getting smaller and rounder.\n",
      "#########################\n",
      "00:01:30.270\n",
      "00:01:35.220\n",
      "The Great Red Spot used to be big enough to fit three Earths. Now, it's just a little over one.\n",
      "#########################\n",
      "00:01:35.220\n",
      "00:01:45.180\n",
      "These discoveries were made by analyzing data from numerous NASA missions, including Voyager, Hubble, and most recently, Juno.\n",
      "#########################\n",
      "00:01:45.180\n",
      "00:01:47.160\n",
      "\n",
      "#########################\n",
      "00:01:47.160\n",
      "00:01:54.120\n",
      "And through more investigations, scientists hope to unlock more secrets of the mysterious Great Red Spot.\n",
      "#########################\n",
      "00:01:54.120\n",
      "00:01:57.120\n",
      "\n",
      "#########################\n",
      "00:01:57.120\n",
      "00:01:58.120\n",
      "\n",
      "#########################\n",
      "00:01:58.120\n",
      "00:01:59.120\n",
      "\n",
      "#########################\n",
      "00:01:59.120\n",
      "00:02:01.080\n",
      "\n",
      "#########################\n",
      "00:02:01.080\n",
      "00:02:05.970\n",
      "\n",
      "#########################\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import re\n",
    "# from typing import List, Dict, Optional\n",
    "# from datetime import datetime\n",
    "# import webvtt\n",
    "# from pathlib import Path\n",
    "\n",
    "# class TranscriptSegment:\n",
    "#     def __init__(self, text: str, start: str, end: str):\n",
    "#         self.text = text\n",
    "#         self.start = start\n",
    "#         self.end = end\n",
    "        \n",
    "#     def to_dict(self) -> Dict:\n",
    "#         return {\n",
    "#             \"text\": self.text,\n",
    "#             \"start_time\": self.start,\n",
    "#             \"end_time\": self.end\n",
    "#         }\n",
    "\n",
    "# class TranscriptProcessor:\n",
    "#     def __init__(self, videos_dir: str, transcripts_dir: str):\n",
    "#         self.videos_dir = Path(videos_dir)\n",
    "#         self.transcripts_dir = Path(transcripts_dir)\n",
    "    \n",
    "#     def parse_vtt(self, vtt_path: str) -> List[TranscriptSegment]:\n",
    "#         \"\"\"Parse a VTT file into segments.\"\"\"\n",
    "#         segments = []\n",
    "#         for caption in webvtt.read(vtt_path):\n",
    "#             # Clean the text: remove multiple spaces and newlines\n",
    "#             text = ' '.join(caption.text.split())\n",
    "#             segments.append(TranscriptSegment(\n",
    "#                 text=text,\n",
    "#                 start=caption.start,\n",
    "#                 end=caption.end\n",
    "#             ))\n",
    "#         return segments\n",
    "    \n",
    "#     def extract_metadata(self, video_path: str, transcript_path: str) -> Dict:\n",
    "#         \"\"\"Extract metadata from video and transcript files.\"\"\"\n",
    "#         video_path = Path(video_path)\n",
    "#         transcript_path = Path(transcript_path)\n",
    "        \n",
    "#         # Get video information\n",
    "#         video_stats = video_path.stat()\n",
    "        \n",
    "#         # Extract timestamp from transcript filename if it exists\n",
    "#         # Format: filename_YYYYMMDD_HHMMSS.vtt\n",
    "#         timestamp_match = re.search(r'_(\\d{8}_\\d{6})\\.vtt$', transcript_path.name)\n",
    "#         processed_date = None\n",
    "#         if timestamp_match:\n",
    "#             date_str = timestamp_match.group(1)\n",
    "#             try:\n",
    "#                 processed_date = datetime.strptime(date_str, '%Y%m%d_%H%M%S').isoformat()\n",
    "#             except ValueError:\n",
    "#                 pass\n",
    "        \n",
    "#         metadata = {\n",
    "#             \"video_filename\": video_path.name,\n",
    "#             \"video_size_bytes\": video_stats.st_size,\n",
    "#             \"video_created_at\": datetime.fromtimestamp(video_stats.st_ctime).isoformat(),\n",
    "#             \"video_modified_at\": datetime.fromtimestamp(video_stats.st_mtime).isoformat(),\n",
    "#             \"transcript_filename\": transcript_path.name,\n",
    "#             \"transcript_processed_at\": processed_date,\n",
    "#             \"file_extension\": video_path.suffix.lower(),\n",
    "#         }\n",
    "        \n",
    "#         return metadata\n",
    "    \n",
    "#     def find_matching_transcript(self, video_filename: str) -> Optional[Path]:\n",
    "#         \"\"\"Find the matching transcript file for a video.\"\"\"\n",
    "#         base_name = Path(video_filename).stem\n",
    "#         matching_transcripts = list(self.transcripts_dir.glob(f\"{base_name}*.vtt\"))\n",
    "        \n",
    "#         if not matching_transcripts:\n",
    "#             return None\n",
    "        \n",
    "#         # Return the most recent transcript if multiple exist\n",
    "#         return sorted(matching_transcripts, key=lambda x: x.stat().st_mtime)[-1]\n",
    "    \n",
    "#     def process_video(self, video_filename: str) -> Optional[Dict]:\n",
    "#         \"\"\"Process a single video and its transcript.\"\"\"\n",
    "#         video_path = self.videos_dir / video_filename\n",
    "#         if not video_path.exists():\n",
    "#             raise FileNotFoundError(f\"Video file not found: {video_filename}\")\n",
    "        \n",
    "#         transcript_path = self.find_matching_transcript(video_filename)\n",
    "#         if not transcript_path:\n",
    "#             raise FileNotFoundError(f\"No matching transcript found for video: {video_filename}\")\n",
    "        \n",
    "#         # Parse the transcript\n",
    "#         segments = self.parse_vtt(str(transcript_path))\n",
    "        \n",
    "#         # Extract metadata\n",
    "#         metadata = self.extract_metadata(video_path, transcript_path)\n",
    "        \n",
    "#         return {\n",
    "#             \"segments\": [seg.to_dict() for seg in segments],\n",
    "#             \"metadata\": metadata\n",
    "#         }\n",
    "    \n",
    "#     def process_all_videos(self) -> List[Dict]:\n",
    "#         \"\"\"Process all videos in the videos directory.\"\"\"\n",
    "#         results = []\n",
    "#         for video_file in self.videos_dir.glob(\"*.mp4\"):\n",
    "#             try:\n",
    "#                 result = self.process_video(video_file.name)\n",
    "#                 if result:\n",
    "#                     results.append(result)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing {video_file.name}: {str(e)}\")\n",
    "#         return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "WEBVTT\n",
    "\n",
    "\n",
    "\n",
    "97afec20-7bee-4318-a470-6822ee7ddbe7/10-0\n",
    "\n",
    "\n",
    "\n",
    "00:00:03.776 --> 00:00:04.816\n",
    "\n",
    "\n",
    "\n",
    "<v Lastname, Firstname Middlename1>I have to go back and look at\n",
    "\n",
    "\n",
    "\n",
    "it.</v>\n",
    "\n",
    "\n",
    "\n",
    "97afec20-7bee-4318-a470-6822ee7ddbe7/14-0\n",
    "\n",
    "\n",
    "\n",
    "00:00:04.816 --> 00:00:08.296\n",
    "\n",
    "\n",
    "\n",
    "<v Lastname, Firstname Middlename1>Typically you also get give me a\n",
    "\n",
    "\n",
    "\n",
    "second.</v>\n",
    "\n",
    "\n",
    "\n",
    "97afec20-7bee-4318-a470-6822ee7ddbe7/20-0\n",
    "\n",
    "\n",
    "\n",
    "00:00:08.856 --> 00:00:11.016\n",
    "\n",
    "\n",
    "\n",
    "<v Lastname, Firstname Middlename1>Is there a multi document which\n",
    "\n",
    "\n",
    "\n",
    "I can share?</v>\n",
    "\n",
    "\n",
    "\n",
    "97afec20-7bee-4318-a470-6822ee7ddbe7/27-0\n",
    "\n",
    "\n",
    "\n",
    "00:00:12.576 --> 00:00:14.176\n",
    "\n",
    "\n",
    "\n",
    "<v Lastname, Firstname Middlename1>There was an MRD document\n",
    "\n",
    "\n",
    "\n",
    "somewhere.</v>\n",
    "\n",
    "\n",
    "\n",
    "97afec20-7bee-4318-a470-6822ee7ddbe7/35-0\n",
    "\n",
    "\n",
    "\n",
    "00:00:20.526 --> 00:00:23.766\n",
    "\n",
    "\n",
    "\n",
    "<v Lastname, Firstname Middlename2>Hsds is a is like the ground\n",
    "\n",
    "\n",
    "\n",
    "truth.</v>\n",
    "\n",
    "\n",
    "\n",
    "97afec20-7bee-4318-a470-6822ee7ddbe7/41-0\n",
    "\n",
    "\n",
    "\n",
    "00:00:25.766 --> 00:00:26.926\n",
    "\n",
    "\n",
    "\n",
    "<v Lastname, Firstname Middlename1>Yeah, that's the ground truth.</v>\n",
    "\n",
    "\n",
    "\n",
    "97afec20-7bee-4318-a470-6822ee7ddbe7/47-0\n",
    "\n",
    "\n",
    "\n",
    "00:00:26.716 --> 00:00:29.756\n",
    "\n",
    "\n",
    "\n",
    "<v Lastname, Firstname Middlename2>From where you create ppts and\n",
    "\n",
    "\n",
    "\n",
    "documents and everything.</v>\n",
    "\n",
    "\n",
    "\n",
    "97afec20-7bee-4318-a470-6822ee7ddbe7/59-0\n",
    "\n",
    "\n",
    "\n",
    "00:00:30.036 --> 00:00:33.600\n",
    "\n",
    "\n",
    "\n",
    "<v Lastname, Firstname Middlename1>Yeah, yeah, yeah. That is the\n",
    "\n",
    "\n",
    "\n",
    "one which has to very clearly</v>\n",
    "\n",
    "\n",
    "\n",
    "97afec20-7bee-4318-a470-6822ee7ddbe7/52-0\n",
    "\n",
    "\n",
    "\n",
    "00:00:31.906 --> 00:00:32.066\n",
    "\n",
    "\n",
    "\n",
    "<v Lastname, Firstname Middlename2>OK.</v>\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
